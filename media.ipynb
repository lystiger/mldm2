{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c452bcf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./venv/lib/python3.12/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.12/site-packages (2.4.1)\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.13.0.92-cp37-abi3-manylinux_2_28_x86_64.whl.metadata (19 kB)\n",
      "Collecting mediapipe\n",
      "  Downloading mediapipe-0.10.32-py3-none-manylinux_2_28_x86_64.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.12/site-packages (from pandas) (2025.3)\n",
      "Collecting absl-py~=2.3 (from mediapipe)\n",
      "  Downloading absl_py-2.4.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting sounddevice~=0.5 (from mediapipe)\n",
      "  Downloading sounddevice-0.5.5-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting flatbuffers~=25.9 (from mediapipe)\n",
      "  Downloading flatbuffers-25.12.19-py2.py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting opencv-contrib-python (from mediapipe)\n",
      "  Downloading opencv_contrib_python-4.13.0.92-cp37-abi3-manylinux_2_28_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: matplotlib in ./venv/lib/python3.12/site-packages (from mediapipe) (3.10.8)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Collecting cffi (from sounddevice~=0.5->mediapipe)\n",
      "  Downloading cffi-2.0.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.12/site-packages (from matplotlib->mediapipe) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.12/site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.12/site-packages (from matplotlib->mediapipe) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./venv/lib/python3.12/site-packages (from matplotlib->mediapipe) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.12/site-packages (from matplotlib->mediapipe) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./venv/lib/python3.12/site-packages (from matplotlib->mediapipe) (12.1.0)\n",
      "Requirement already satisfied: pyparsing>=3 in ./venv/lib/python3.12/site-packages (from matplotlib->mediapipe) (3.3.1)\n",
      "Collecting pycparser (from cffi->sounddevice~=0.5->mediapipe)\n",
      "  Downloading pycparser-3.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Downloading opencv_python-4.13.0.92-cp37-abi3-manylinux_2_28_x86_64.whl (72.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading mediapipe-0.10.32-py3-none-manylinux_2_28_x86_64.whl (10.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.4.0-py3-none-any.whl (135 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading flatbuffers-25.12.19-py2.py3-none-any.whl (26 kB)\n",
      "Downloading sounddevice-0.5.5-py3-none-any.whl (32 kB)\n",
      "Downloading opencv_contrib_python-4.13.0.92-cp37-abi3-manylinux_2_28_x86_64.whl (79.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.2/79.2 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading cffi-2.0.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (219 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.6/219.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pycparser-3.0-py3-none-any.whl (48 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: flatbuffers, pycparser, opencv-python, opencv-contrib-python, absl-py, cffi, sounddevice, mediapipe\n",
      "Successfully installed absl-py-2.4.0 cffi-2.0.0 flatbuffers-25.12.19 mediapipe-0.10.32 opencv-contrib-python-4.13.0.92 opencv-python-4.13.0.92 pycparser-3.0 sounddevice-0.5.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy opencv-python mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee31f827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9787bdd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1772027845.177230   19340 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1772027845.198020   19950 gl_context.cc:369] GL version: 3.0 (OpenGL ES 3.0 Mesa 25.0.7-0ubuntu0.24.04.2), renderer: Mesa Intel(R) HD Graphics 4000 (IVB GT2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1772027845.272575   19947 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1772027845.308520   19946 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "\n",
    "hands = mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=2,\n",
    "    min_detection_confidence=0.6,\n",
    "    min_tracking_confidence=0.6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d25cb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hand(hand_landmarks):\n",
    "    feat = []\n",
    "    for lm in hand_landmarks.landmark:\n",
    "        feat.extend([lm.x, lm.y, lm.z])\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b633e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "q : quit\n",
      "c : toggle collect\n",
      "1-9 : set gesture (gesture_1, gesture_2...)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring XDG_SESSION_TYPE=wayland on Gnome. Use QT_QPA_PLATFORM=wayland to run on Wayland anyway.\n",
      "W0000 00:00:1772027855.466982   19946 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\"\"\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[33mq : quit\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[33mc : toggle collect\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[33m1-9 : set gesture (gesture_1, gesture_2...)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[33m\"\"\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m cap.isOpened():\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     ret, frame = \u001b[43mcap\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[32m     16\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "current_gesture = \"none\"\n",
    "collecting = False\n",
    "records = []\n",
    "\n",
    "print(\"\"\"\n",
    "q : quit\n",
    "c : toggle collect\n",
    "1-9 : set gesture (gesture_1, gesture_2...)\n",
    "\"\"\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    res = hands.process(rgb)\n",
    "\n",
    "    L_feat = [0.0] * 63\n",
    "    R_feat = [0.0] * 63\n",
    "    L_exist = 0\n",
    "    R_exist = 0\n",
    "\n",
    "    if res.multi_hand_landmarks:\n",
    "        for hand_lm, handedness in zip(\n",
    "            res.multi_hand_landmarks,\n",
    "            res.multi_handedness\n",
    "        ):\n",
    "            label = handedness.classification[0].label\n",
    "            feat = extract_hand(hand_lm)\n",
    "\n",
    "            if label == \"Left\":\n",
    "                L_feat = feat\n",
    "                L_exist = 1\n",
    "            else:\n",
    "                R_feat = feat\n",
    "                R_exist = 1\n",
    "\n",
    "            mp_draw.draw_landmarks(\n",
    "                frame, hand_lm, mp_hands.HAND_CONNECTIONS\n",
    "            )\n",
    "\n",
    "    if collecting:\n",
    "        row = (\n",
    "            [current_gesture, L_exist, R_exist]\n",
    "            + L_feat\n",
    "            + R_feat\n",
    "        )\n",
    "        records.append(row)\n",
    "\n",
    "    cv2.putText(\n",
    "        frame,\n",
    "        f\"Gesture: {current_gesture} | Collecting: {collecting}\",\n",
    "        (10, 30),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        0.7,\n",
    "        (0, 255, 0) if collecting else (0, 0, 255),\n",
    "        2\n",
    "    )\n",
    "\n",
    "    cv2.imshow(\"Landmark Collector\", frame)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "    elif key == ord(\"c\"):\n",
    "        collecting = not collecting\n",
    "        print(\"Collecting:\", collecting)\n",
    "    elif ord(\"1\") <= key <= ord(\"9\"):\n",
    "        current_gesture = f\"gesture_{key - ord('0')}\"\n",
    "        print(\"Gesture set:\", current_gesture)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bba435cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: (136, 129)\n"
     ]
    }
   ],
   "source": [
    "columns = (\n",
    "    [\"gesture\", \"L_exist\", \"R_exist\"]\n",
    "    + [f\"L_{a}{i}\" for i in range(21) for a in [\"x\",\"y\",\"z\"]]\n",
    "    + [f\"R_{a}{i}\" for i in range(21) for a in [\"x\",\"y\",\"z\"]]\n",
    ")\n",
    "\n",
    "df = pd.DataFrame(records, columns=columns)\n",
    "df.to_csv(\"hand_landmarks.csv\", index=False)\n",
    "print(\"Saved:\", df.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
