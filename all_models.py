import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score

# Import 4 "vÅ© khÃ­" háº¡ng náº·ng cá»§a ML truyá»n thá»‘ng
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression

# ==========================================
# 0. CHUáº¨N Bá»Š Dá»® LIá»†U 
# ==========================================
# Giáº£ láº­p data (Thay báº±ng X_ML vÃ  y_labels thá»±c táº¿ cá»§a cáº­u)
np.random.seed(42)
X_ML = np.random.rand(600, 34) 
y_labels = np.array(['A']*200 + ['B']*200 + ['C']*200)

X_train, X_test, y_train, y_test = train_test_split(X_ML, y_labels, test_size=0.2, random_state=42)

# ==========================================
# 1. BÆ¯á»šC Sá»NG CÃ’N: CHUáº¨N HÃ“A Dá»® LIá»†U (FEATURE SCALING)
# ==========================================
scaler = StandardScaler()
# Cho Scaler há»c tá»« táº­p Train, sau Ä‘Ã³ biáº¿n Ä‘á»•i cáº£ Train vÃ  Test
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# ==========================================
# 2. KHAI BÃO CÃC MÃ” HÃŒNH
# ==========================================
models = {
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "SVM (RBF Kernel)": SVC(kernel='rbf', probability=True, random_state=42),
    "KNN (K=5)": KNeighborsClassifier(n_neighbors=5),
    "Logistic Regression": LogisticRegression(max_iter=2000, random_state=42)
}

# ==========================================
# 3. TRAIN VÃ€ ÄÃNH GIÃ Äá»’NG LOáº T
# ==========================================
print("ğŸš€ Báº®T Äáº¦U CHáº Y ÄUA CÃC MÃ” HÃŒNH...\n")
results = {}

for name, model in models.items():
    # Nhá»› dÃ¹ng data Ä‘Ã£ Scaled nhÃ©!
    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_test_scaled)
    
    acc = accuracy_score(y_test, y_pred)
    results[name] = acc * 100
    print(f"âœ… {name:20s} : Äá»™ chÃ­nh xÃ¡c {results[name]:.2f}%")

# ==========================================
# 4. Váº¼ BIá»‚U Äá»’ SO SÃNH DÃN VÃ€O BÃO CÃO
# ==========================================
plt.figure(figsize=(10, 6))
# Váº½ biá»ƒu Ä‘á»“ cá»™t
bars = plt.bar(results.keys(), results.values(), color=['#4CAF50', '#2196F3', '#FFC107', '#E91E63'])

# Gáº¯n sá»‘ % lÃªn Ä‘áº§u má»—i cá»™t cho chuyÃªn nghiá»‡p
for bar in bars:
    yval = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, yval + 1, f'{yval:.1f}%', ha='center', va='bottom', fontweight='bold')

plt.ylim(0, 110) # Äá»ƒ trá»¥c Y cao hÆ¡n 100 má»™t xÃ­u cho Ä‘áº¹p
plt.title('So sÃ¡nh Hiá»‡u nÄƒng cÃ¡c thuáº­t toÃ¡n Machine Learning', fontsize=14, fontweight='bold')
plt.ylabel('Äá»™ chÃ­nh xÃ¡c (Accuracy %)', fontsize=12)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.show()  
